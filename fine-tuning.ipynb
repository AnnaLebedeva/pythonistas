{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "698225a7",
   "metadata": {
    "cellId": "g0ed22x3i0tzdkk26ms9l"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b65a72c8",
   "metadata": {
    "cellId": "reue9y8l4cqqpzei8u1eoa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>1category</th>\n",
       "      <th>2category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4754</td>\n",
       "      <td>При этом всегда получал качественные услуги.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4417</td>\n",
       "      <td>Не вижу, за что хотя бы 2 поставить, сервис на 1!</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3629</td>\n",
       "      <td>Вот так \"Мой любимый\" банк МКБ меня обманул.</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11640</td>\n",
       "      <td>Отвратительное отношение к клиентам.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5571</td>\n",
       "      <td>Всегда в любое время дня и ночи помогут, ответ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5254</td>\n",
       "      <td>Все время согласовывалось, всё делалось быстро.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16243</td>\n",
       "      <td>Абсолютное бездействие и нежелание банка работ...</td>\n",
       "      <td>Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20223</td>\n",
       "      <td>Первая операция на внесение 122 000 руб. была ...</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9383</td>\n",
       "      <td>Ну почему я опять должен звонить и платить ден...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5185</td>\n",
       "      <td>Получив карту \"Кредит в кармане\" и две бесплат...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ... sentiment\n",
       "0        4754  ...         +\n",
       "1        4417  ...         −\n",
       "2        3629  ...         −\n",
       "3       11640  ...         −\n",
       "4        5571  ...         +\n",
       "5        5254  ...         +\n",
       "6       16243  ...         −\n",
       "7       20223  ...         ?\n",
       "8        9383  ...         −\n",
       "9        5185  ...         +\n",
       "\n",
       "[10 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "data = pd.read_csv(\"datasets/hse_data_science_hack/train.csv\", index_col=False)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0719493",
   "metadata": {
    "cellId": "vyblt3xd79r0slnylcvyxh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b0ee433",
   "metadata": {
    "cellId": "6a0vflofph9vc3rkqo2g9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015c33367ca648979e8e0212fcbff1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2812b3eaaf5d4d91aa5e44ab8807ecaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=642.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9132c30cf1004a1f90e6d4e6b0400292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1649718.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b32e1a4ff24a6a9512d7df8d5201e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b80938ae5d4de2aa2e786fc13f7829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=714355318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model_bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\").to(device)\n",
    "for param in model_bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6c5a051",
   "metadata": {
    "cellId": "21fl1rsx2mdjxje9hq4g82d"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer, texts, targets):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = [torch.LongTensor(tokenizer.encode(t)) for t in texts]\n",
    "        self.texts = torch.nn.utils.rnn.pad_sequence(\n",
    "            self.texts, \n",
    "            batch_first=True,\n",
    "            padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        self.length = len(texts)\n",
    "        self.target = torch.LongTensor(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ids = self.texts[index]\n",
    "        y = self.target[index]\n",
    "        return ids, y\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        tokens = text.lower().split()\n",
    "        tokens = [token.strip(punctuation) for token in tokens]\n",
    "        tokens = [token for token in tokens if token]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecaa239a",
   "metadata": {
    "cellId": "iscy36c44juxn3dc9q1"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "texts = data.sentence.values\n",
    "id2label = {i: l for i, l in enumerate(set(data.sentiment.values))}\n",
    "label2id = {l: i for i, l in id2label.items()}\n",
    "targets = [label2id[l] for l in data.sentiment.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc3510c0",
   "metadata": {
    "cellId": "nuyetmjorsdnard7a2ncs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_texts, valid_texts, train_targets, valid_targets = train_test_split(texts, targets, test_size=0.05, stratify=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c00f39ee",
   "metadata": {
    "cellId": "n6dp4cwxd27oqr5f92hat"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "training_set = Dataset(tokenizer, train_texts, train_targets)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True)\n",
    "valid_set = Dataset(tokenizer, valid_texts, valid_targets)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1182f9d0",
   "metadata": {
    "cellId": "sfzb26l702bhhrw0gxt5gl"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class CLF(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, pretrained_model, num_classes):\n",
    "        super().__init__()          \n",
    "        self.tokenizer = tokenizer\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.linear_1 = nn.Linear(768, 256)\n",
    "        self.linear_2 = nn.Linear(256, num_classes) \n",
    "        self.activation = nn.LogSoftmax(1) \n",
    "        \n",
    "    def forward(self, texts):\n",
    "        mask = (texts != tokenizer.pad_token_id).long()\n",
    "        hidden = self.pretrained_model(texts, attention_mask=mask)[0]\n",
    "        dense_outputs_1 = self.linear_1(hidden[:,0])\n",
    "        outputs_1 = self.activation(dense_outputs_1)\n",
    "        dense_outputs = self.linear_2(dense_outputs_1)\n",
    "        outputs=self.activation(dense_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d980dab",
   "metadata": {
    "cellId": "q46tgzkja8nruixrtrxo5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_score = []\n",
    "    \n",
    "    model.train()  \n",
    "\n",
    "    for texts, ys in tqdm(iterator):\n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "        predictions = model(texts.to(device)).squeeze()\n",
    "        loss = criterion(predictions, ys.to(device))        \n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        preds = predictions.detach().to(\"cpu\").numpy().argmax(1).tolist()\n",
    "        y_true = ys.tolist()\n",
    "        epoch_loss.append(loss.item())\n",
    "        epoch_score.append(f1_score(y_true, preds, average=\"macro\"))\n",
    "\n",
    "    return np.mean(epoch_loss), np.mean(epoch_score)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = []\n",
    "    epoch_score = []\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for texts, ys in tqdm(iterator):   \n",
    "            predictions = model(texts.to(device)).squeeze()  \n",
    "            loss = criterion(predictions, ys.to(device))        \n",
    "            preds = predictions.detach().to(\"cpu\").numpy().argmax(1).tolist()\n",
    "            y_true = ys.tolist()\n",
    "            epoch_loss.append(loss.item())  \n",
    "            epoch_score.append(f1_score(y_true, preds, average=\"macro\"))\n",
    "\n",
    "    return np.mean(epoch_loss), np.mean(epoch_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8f16d82",
   "metadata": {
    "cellId": "107tt63y34kbonnytqxbu7"
   },
   "outputs": [],
   "source": [
    "#!g1.4\n",
    "model = CLF(model_bert, len(label2id))\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-6)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.05)\n",
    "criterion = nn.NLLLoss() \n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c53f2",
   "metadata": {
    "cellId": "6nkvwzo5fcxrkw65bgn27",
    "execution_id": "f4fec61d-f99f-4b54-9403-75808b57183a"
   },
   "outputs": [],
   "source": [
    "#!g1.4\n",
    "EPOCHS = 200\n",
    "\n",
    "train_losses = []\n",
    "train_evals = []\n",
    "valid_losses = []\n",
    "valid_evals = []\n",
    "\n",
    "best_valid_loss = 1e+6\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    print(f\"Epoch: {i+1}\")\n",
    "\n",
    "    train_loss, train_score = train(model, training_generator, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_evals.append(train_score)\n",
    "    print(f\"Train loss: {train_loss}, Train score: {train_score}\")\n",
    "\n",
    "    val_loss, val_score = evaluate(model, valid_generator, criterion)\n",
    "    valid_losses.append(val_loss)\n",
    "    valid_evals.append(val_score)\n",
    "    print(f\"Valid loss: {val_loss}, Valid score: {val_score}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(), f\"/home/jupyter/mnt/s3/cheliki/rubert_finetuned/state_dict_model.pth\")\n",
    "        torch.save(optimizer.state_dict(), f\"/home/jupyter/mnt/s3/cheliki/rubert_finetuned/state_dict_optimizer.pth\")\n",
    "    \n",
    "    with open(f'/home/jupyter/mnt/s3/cheliki/rubert_finetuned/info.json', 'w') as file_object:\n",
    "                info = {\n",
    "                    'train_losses': train_losses,\n",
    "                    'train_evals': train_evals,\n",
    "                }\n",
    "                file_object.write(json.dumps(info, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "42b89d48-b577-48d0-a865-ab1f3b0d6bc5",
  "notebookPath": "fine-tuning.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
